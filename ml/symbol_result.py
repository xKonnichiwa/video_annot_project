# --- Библиотеки для обработки изображений ---
import cv2  # Импортируем библиотеку OpenCV для обработки изображений и видео (например, чтение кадров, фильтрация и детектирование)
import os  # Библиотека для работы с файловой системой (проверка существования файлов, создание папок, обработка путей)
import pytesseract  # Интерфейс для Tesseract OCR — используется для распознавания текста на изображениях

# --- Библиотеки для работы с изображениями и их фильтрации ---
from PIL import Image, ImageEnhance, ImageFilter  # Импортируем модули из PIL для работы с изображениями (открытие, обработка, фильтрация)

# --- Стандартные библиотеки Python ---
import glob  # Библиотека для поиска файлов по шаблону (например, найти все изображения .png в папке)
import json  # Библиотека для работы с JSON файлами (чтение, запись, парсинг)


# Путь к Tesseract на вашей системе
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

def extract_frames(video_path, output_folder):
    """
    Извлекает кадры из видеофайла каждую секунду и сохраняет их в указанную папку.

    Аргументы:
    video_path — путь к входному видеофайлу.
                 Пример: 'input_video.mp4'.
    output_folder — путь к папке, куда будут сохранены извлеченные кадры.
                    Пример: 'frames/'.

    Описание:
    - Функция извлекает один кадр из видео за каждую секунду, основываясь на FPS (кадрах в секунду).
    - Кадры сохраняются в указанную папку `output_folder` с именами в формате 'frame_{номер_кадра}.jpg'.
    - Если видеофайл не удается открыть, выводится сообщение об ошибке.
    """
    
    # --- Шаг 1: Создание выходной папки для сохранения кадров ---
    
    os.makedirs(output_folder, exist_ok=True)  # Создаем папку, если она не существует

    # --- Шаг 2: Открытие видеофайла с помощью OpenCV ---
    
    video = cv2.VideoCapture(video_path)  # Открытие видеофайла

    # Проверка, удалось ли открыть видео
    if not video.isOpened():
        print(f"Не удалось открыть видеофайл {video_path}")  # Вывод сообщения об ошибке
        return  # Завершаем функцию, если видео не открыто

    # --- Шаг 3: Извлечение кадровой частоты (FPS) ---
    
    fps = video.get(cv2.CAP_PROP_FPS)  # Получаем частоту кадров (FPS) видеофайла
    frame_interval = int(fps)  # Определяем интервал кадров: 1 кадр в секунду (соответствует количеству кадров в 1 секунде)

    # --- Шаг 4: Инициализация переменных для прохода по кадрам ---
    
    success, frame = video.read()  # Чтение первого кадра
    count = 0  # Счетчик текущего кадра
    saved_frame_count = 0  # Счетчик сохраненных кадров

    # --- Шаг 5: Проход по всем кадрам в видео ---
    
    while success:  # Пока удается прочитать следующий кадр
        # --- Шаг 6: Сохранение кадра каждую секунду ---
        
        # Если текущий кадр соответствует интервалу (каждая секунда), то сохраняем его
        if count % frame_interval == 0:
            frame_path = f"{output_folder}/frame_{saved_frame_count}.jpg"  # Формируем путь для сохранения кадра
            cv2.imwrite(frame_path, frame)  # Сохраняем кадр как изображение в формате .jpg
            saved_frame_count += 1  # Увеличиваем счетчик сохраненных кадров

        # --- Шаг 7: Переход к следующему кадру ---
        
        success, frame = video.read()  # Чтение следующего кадра
        count += 1  # Увеличиваем счетчик кадров

    # --- Шаг 8: Завершение работы с видео ---
    
    video.release()  # Освобождаем объект видеофайла
    print(f"Извлечено {saved_frame_count} кадров.")  # Сообщение о количестве извлеченных кадров

def preprocess_image(image):
    """
    Выполняет предварительную обработку изображения перед его распознаванием (например, с помощью OCR).
    Осуществляет преобразование в черно-белый формат, повышение контраста и улучшение резкости.
    
    Аргументы:
    image — входное изображение, объект PIL (например, Image.open('image.png')).
    
    Возвращает:
    Обработанное изображение после применения преобразований.

    Описание:
    - Преобразование изображения в черно-белый формат.
    - Увеличение контраста для улучшения четкости текста.
    - Применение фильтра для уменьшения шума и повышения резкости.
    """

    # --- Шаг 1: Преобразование изображения в черно-белый формат (градации серого) ---
    
    # Используем метод `convert('L')` для преобразования изображения в 8-битное черно-белое (монохромное).
    # Это уменьшает количество цветов и упрощает дальнейшую обработку изображения, делая его одноканальным.
    image = image.convert('L')

    # --- Шаг 2: Увеличение контраста изображения ---
    
    # Создаем объект `ImageEnhance.Contrast` для управления контрастом изображения.
    # Контраст помогает выделить текст и другие мелкие детали, делая изображение более четким.
    enhancer = ImageEnhance.Contrast(image)
    
    # Применяем увеличение контраста: коэффициент `2` означает, что контраст будет увеличен в 2 раза.
    # Значения >1 увеличивают контраст, значения <1 — уменьшают.
    image = enhancer.enhance(2)

    # --- Шаг 3: Применение фильтра для уменьшения шума и повышения резкости ---
    
    # Используем фильтр `ImageFilter.SHARPEN` для повышения резкости изображения.
    # Фильтр устраняет некоторые шумы и делает текстовые элементы более четкими, что улучшает распознавание.
    image = image.filter(ImageFilter.SHARPEN)

    # --- Возврат обработанного изображения ---
    
    return image  # Возвращаем улучшенное изображение

def ocr_image(image_path):
    """
    Выполняет распознавание текста на изображении с использованием Tesseract OCR.
    
    Аргументы:
    image_path — путь к изображению, которое нужно обработать.
                 Пример: 'images/sample_image.png'.

    Возвращает:
    Извлеченный текст в виде строки.

    Описание:
    - Открывает изображение по указанному пути.
    - Выполняет предварительную обработку изображения для улучшения качества распознавания.
    - Применяет Tesseract для извлечения текста на двух языках (английском и русском).
    """

    # --- Шаг 1: Открытие изображения ---
    
    # Открываем изображение с помощью библиотеки PIL (Pillow).
    # `Image.open(image_path)` загружает изображение в память как объект `Image`.
    image = Image.open(image_path)

    # --- Шаг 2: Предварительная обработка изображения ---
    
    # Применяем функцию `preprocess_image` для улучшения качества изображения.
    # Улучшенное изображение возвращается в переменную `image`.
    image = preprocess_image(image)

    # --- Шаг 3: Извлечение текста с помощью Tesseract OCR ---
    
    # `pytesseract.image_to_string` выполняет распознавание текста на изображении.
    # `lang='eng+rus'` указывает на использование сразу двух языков: английского ('eng') и русского ('rus').
    # Это позволяет распознавать как английские, так и русские символы на одном изображении.
    text = pytesseract.image_to_string(image, lang='eng+rus')

    # --- Возвращение извлеченного текста ---
    
    return text  # Возвращаем распознанный текст

def analyze_all_frames(frames_folder):
    """
    Выполняет анализ всех кадров в указанной папке и распознает текст на каждом кадре с помощью OCR.

    Аргументы:
    frames_folder — папка, содержащая кадры, извлеченные из видео.
                    Пример: 'frames/'.

    Возвращает:
    Список словарей, где каждый словарь содержит имя кадра и распознанный текст:
    [{'frame': 'frame_0.jpg', 'text': 'Распознанный текст...'}, ...]

    Описание:
    - Считывает все файлы кадров из указанной папки, которые соответствуют шаблону 'frame_*.jpg'.
    - Сортирует их по номеру кадра, чтобы анализировать кадры в правильной последовательности.
    - Применяет функцию `ocr_image` для распознавания текста на каждом кадре.
    - Сохраняет результаты распознавания в список, если текст не пустой.
    """
    
    # --- Шаг 1: Получение списка всех кадров в папке ---
    
    # Используем `glob.glob` для поиска всех файлов, соответствующих шаблону 'frame_*.jpg'.
    # Путь формируется как f"{frames_folder}/frame_*.jpg", что позволяет находить все кадры с именами 'frame_0.jpg', 'frame_1.jpg' и т.д.
    frame_files = glob.glob(f"{frames_folder}/frame_*.jpg")

    # --- Шаг 2: Сортировка файлов по номеру кадра ---
    
    # Файлы сортируются по номеру кадра, чтобы анализировать их в порядке их появления.
    # Извлекаем номер кадра с помощью `os.path.splitext` и `os.path.basename`, затем сортируем по нему.
    # Пример: 'frame_10.jpg' -> извлекается 10 -> сортируется по возрастанию.
    frame_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[1]))

    # --- Шаг 3: Проверка наличия кадров в папке ---
    
    # Если список кадров пуст, выводим сообщение и завершаем выполнение функции.
    if not frame_files:
        print(f"В папке {frames_folder} нет изображений для анализа.")
        return []  # Возвращаем пустой список, если нет кадров для анализа

    # --- Шаг 4: Инициализация списка для хранения результатов распознавания ---
    
    all_texts = []  # Пустой список для хранения всех результатов OCR

    # --- Шаг 5: Проход по каждому кадру и выполнение OCR ---
    
    for frame_file in frame_files:
        # `frame_file` — путь к текущему кадру (например, 'frames/frame_0.jpg')
        
        # Выполняем распознавание текста с помощью функции `ocr_image`
        text = ocr_image(frame_file)

        # --- Шаг 6: Сохранение текста, если он не пустой ---
        
        if text.strip():  # Проверяем, что текст не пустой после удаления пробелов
            print(f"На кадре {frame_file} распознан текст: {text}")  # Выводим распознанный текст
            all_texts.append({"frame": frame_file, "text": text})  # Добавляем результат в список

    # --- Шаг 7: Возврат списка результатов OCR ---
    
    return all_texts  # Возвращаем список с распознанными текстами для всех кадров

def save_results_to_json(all_texts, output_file):
    """
    Сохраняет результаты анализа в указанный JSON файл.
    
    Аргументы:
    all_texts — список результатов анализа, каждый элемент — словарь с информацией о кадре и тексте.
                Пример: [{'frame': 'frame_0.jpg', 'text': 'Распознанный текст...'}, ...].
                
    output_file — имя или путь к выходному JSON файлу.
                  Пример: 'ocr_results.json'.

    Описание:
    - Открывает указанный файл на запись с поддержкой кодировки UTF-8.
    - Записывает список `all_texts` в формате JSON с параметрами `ensure_ascii=False` и `indent=4`.
    - Параметр `ensure_ascii=False` используется для сохранения текста в читаемом виде, включая символы кириллицы.
    - Параметр `indent=4` делает формат JSON файла более структурированным и удобным для чтения.
    """

    # --- Шаг 1: Открытие файла на запись ---
    
    # Открываем файл на запись ('w') и устанавливаем кодировку 'utf-8'.
    # Если файла `output_file` не существует, он будет создан.
    with open(output_file, 'w', encoding='utf-8') as f:

        # --- Шаг 2: Запись данных в формате JSON ---
        
        # Сохраняем данные `all_texts` в формате JSON в открытый файл.
        # - `ensure_ascii=False` сохраняет текст в читаемом виде (например, кириллицу и символы других языков).
        # - `indent=4` добавляет отступы для более удобного иерархического отображения.
        json.dump(all_texts, f, ensure_ascii=False, indent=4)

    # На этом этапе файл автоматически закрывается после выхода из блока `with`.

def process_video(video_path, output_folder, output_file):
    """
    Основная функция для выполнения всех шагов анализа видеофайла:
    - Извлечение кадров каждую секунду.
    - Распознавание текста на каждом кадре.
    - Сохранение результатов в JSON файл.
    
    Аргументы:
    video_path — путь к исходному видеофайлу.
                 Пример: 'videos/input_video.mp4'.
                 
    output_folder — папка для сохранения извлеченных кадров.
                    Пример: 'frames/'.
                    
    output_file — имя или путь к выходному JSON файлу.
                  Пример: 'ocr_results.json'.

    Описание:
    - Шаг 1: Извлекает кадры из видеофайла каждую секунду и сохраняет их в папку `output_folder`.
    - Шаг 2: Выполняет анализ всех извлеченных кадров с помощью функции OCR, чтобы распознать текст на изображениях.
    - Шаг 3: Сохраняет результаты анализа (кадр + распознанный текст) в формате JSON в указанный файл `output_file`.
    - По завершении выводит сообщение с указанием пути к сохраненному файлу JSON.
    """

    # --- Шаг 1: Извлечение кадров из видео каждую секунду ---
    
    # Используем функцию `extract_frames` для извлечения кадров из видео.
    # Все кадры будут сохранены в указанную папку `output_folder` с именами, например, `frame_0.jpg`, `frame_1.jpg` и т.д.
    extract_frames(video_path, output_folder)
    
    # --- Шаг 2: Анализ символов на всех кадрах ---
    
    # Выполняем анализ текста на всех извлеченных кадрах, используя функцию `analyze_all_frames`.
    # Возвращается список словарей, где каждый элемент содержит имя кадра и распознанный текст.
    all_texts = analyze_all_frames(output_folder)
    
    # --- Шаг 3: Сохранение результатов в JSON файл ---
    
    # Сохраняем все результаты анализа в выходной JSON файл, используя функцию `save_results_to_json`.
    # Формат файла: [{'frame': 'frame_0.jpg', 'text': 'Распознанный текст...'}, ...]
    save_results_to_json(all_texts, output_file)
    
    # --- Завершение: Вывод сообщения о завершении ---
    
    print(f"Результаты анализа сохранены в файл {output_file}.")  # Вывод сообщения об успешном сохранении результатов

# Пример использования функции обработки видео
if __name__ == "__main__":
    """
    Этот блок кода выполняется только при запуске этого файла напрямую (например, python script.py).
    Если файл подключается как модуль, этот блок не будет выполнен.
    """

    # --- Шаг 1: Определение параметров для анализа ---
    
    # Указываем путь к видеофайлу, который нужно проанализировать.
    # Замените '4.mp4' на нужный вам видеофайл. Можно использовать относительный или абсолютный путь.
    video_path = '4.mp4'  # Пример: 'videos/sample_video.mp4'
    
    # Задаем папку для сохранения извлеченных кадров.
    # Если папка не существует, она будет создана автоматически функцией `extract_frames`.
    output_folder = 'frames'  # Папка для хранения кадров. Пример: 'frames_output/'
    
    # Имя или путь к файлу для сохранения результатов анализа.
    # Результаты будут сохранены в формате JSON.
    output_file = 'analyzed_texts.json'  # Пример: 'results/ocr_results.json'

    # --- Шаг 2: Запуск функции для обработки видео ---
    
    # Запускаем основную функцию `process_video` для выполнения всех шагов анализа.
    # Функция извлечет кадры, выполнит анализ текста и сохранит результаты.
    process_video(video_path, output_folder, output_file)
