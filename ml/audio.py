import json  # Импорт модуля для работы с JSON-форматом
import os  # Импорт модуля для работы с файловой системой и операциями с путями
import numpy as np  # Импорт библиотеки для работы с числовыми массивами и математическими операциями
import librosa  # Импорт библиотеки для обработки и анализа аудио
from moviepy.editor import VideoFileClip  # Импорт класса для работы с видеоклипами из библиотеки MoviePy
import speech_recognition as sr  # Импорт библиотеки для распознавания речи
import soundfile as sf  # Импорт модуля для работы с аудиофайлами (запись/чтение)
from transformers import pipeline  # Импорт метода для создания NLP-пайплайнов из библиотеки Transformers
from msclap import CLAP  # Импорт модели CLAP для анализа типов звуков
import argparse  # Импорт модуля для обработки аргументов командной строки



# Функция для извлечения аудиодорожки из видеофайла и сохранения ее в формате .wav
def extract_audio_from_video(video_path):
    """
    Извлекает аудиодорожку из указанного видеофайла и сохраняет ее как файл .wav.

    Аргументы:
    video_path — путь к видеофайлу, из которого нужно извлечь аудиодорожку.

    Возвращает:
    output_audio_path — путь к созданному аудиофайлу в формате .wav.
    Если происходит ошибка, возвращает None.
    """

    # Формируем путь к выходному аудиофайлу, используя имя видеофайла и меняя расширение на .wav
    output_audio_path = os.path.splitext(video_path)[0] + ".wav"

    try:
        # --- Извлечение аудиодорожки из видео ---
        
        # Загружаем видеофайл с помощью VideoFileClip
        video = VideoFileClip(video_path)

        # Извлекаем аудиодорожку из видео (объект audio связан с VideoFileClip)
        audio = video.audio

        # Сохраняем аудиодорожку как отдельный .wav файл
        audio.write_audiofile(output_audio_path)

        # Уведомление об успешном сохранении аудио
        print(f"Аудиодорожка успешно сохранена в {output_audio_path}")

        # Возвращаем путь к сохраненному аудиофайлу
        return output_audio_path

    except Exception as e:
        # Если возникает ошибка (например, файл не найден или проблема с кодеком), выводим сообщение об ошибке
        print(f"Произошла ошибка: {e}")

        # Возвращаем None в случае ошибки
        return None

# Функция для очистки и нормализации текста
def clean_text(text):
    """
    Выполняет очистку текста, удаляя нежелательные символы и пробелы, а также нормализует кодировку.

    Аргументы:
    text — строка (text), которую необходимо очистить.

    Возвращает:
    Очищенный и нормализованный текст, в котором удалены ненужные символы и пробельные символы.
    """

    # --- Шаг 1: Удаление некорректных символов через нормализацию кодировки ---
    
    # Преобразуем текст в формат UTF-8, игнорируя символы, которые не могут быть закодированы.
    # Затем декодируем его обратно в строку UTF-8. Это позволяет избавиться от некорректных или нераспознаваемых символов.
    clean_text = text.encode('utf-8', 'ignore').decode('utf-8', 'ignore')

    # --- Шаг 2: Удаление символов новой строки и возврата каретки ---
    
    # Заменяем все символы новой строки ('\n') на пробелы
    clean_text = clean_text.replace('\n', ' ')
    
    # Заменяем символы возврата каретки ('\r') на пробелы
    clean_text = clean_text.replace('\r', ' ')
    
    # --- Шаг 3: Удаление лишних пробелов и символов в начале и конце строки ---
    
    # Удаляем лишние пробелы в начале и конце строки с помощью метода .strip()
    clean_text = clean_text.strip()
    
    # Возвращаем очищенный текст
    return clean_text

# Функция для генерации суммаризаций на русском языке на основе текста транскрипций
def generate_summary_russian(transcriptions):
    """
    Выполняет суммаризацию текстов из транскрипций на русском языке с использованием модели "cointegrated/rut5-base-absum".

    Аргументы:
    transcriptions — список транскрипций, каждая из которых представлена как словарь с ключами:
        - 'text': исходный текст транскрипции.
        - 'timestamp': временная метка начала этой транскрипции (например, для синхронизации с видео).

    Возвращает:
    summary_results — список словарей, каждый из которых содержит:
        - 'timestamp': временная метка транскрипции.
        - 'summary': краткая суммаризация текста.
        - 'original_text': исходный текст транскрипции после очистки.
    """

    # --- Инициализация модели суммаризации ---
    
    # Создаем объект для суммаризации, используя предобученную модель "cointegrated/rut5-base-absum".
    # Эта модель оптимизирована для выполнения абстрактной суммаризации текстов на русском языке.
    summarizer = pipeline("summarization", model="cointegrated/rut5-base-absum")

    # Инициализация пустого списка для хранения результатов суммаризации
    summary_results = []

    # --- Проход по каждой транскрипции в списке ---
    
    for item in transcriptions:
        text = clean_text(item['text'])  # Очищаем текст транскрипции с помощью функции clean_text
        timestamp = item['timestamp']  # Получаем временную метку для текущей транскрипции

        try:
            # Выполняем суммаризацию текста, задав минимальную и максимальную длину результата
            summary = summarizer(text, max_length=50, min_length=10, do_sample=False)[0]['summary_text']
        except Exception as e:
            # Если возникает ошибка при суммаризации, сохраняем специальную метку и выводим сообщение об ошибке
            summary = "[Ошибка суммаризации]"
            print(f"Ошибка суммаризации для текста '{text}': {e}")

        # Добавляем результат суммаризации в список
        summary_results.append({
            "timestamp": timestamp,  # Временная метка транскрипции
            "summary": summary,  # Суммаризация текста или сообщение об ошибке
            "original_text": text  # Оригинальный очищенный текст транскрипции
        })

    # Возвращаем список с результатами суммаризации
    return summary_results

# Функция для загрузки аудиофайла и его транскрипции
def split_audio_and_transcribe(audio_path):
    """
    Загружает аудиофайл, разделяет его на фрагменты (при необходимости) и выполняет распознавание речи.

    Аргументы:
    audio_path — путь к аудиофайлу, который нужно транскрибировать.

    Возвращает:
    transcription_results — список словарей, каждый из которых содержит:
        - 'text': распознанный текст (или сообщение об ошибке).
        - 'timestamp': временная метка начала (для текущей реализации фиксированное значение 0).
    """

    # --- Шаг 1: Загрузка аудиофайла с помощью библиотеки librosa ---
    
    # Загружаем аудиофайл и получаем аудиоданные (waveform) и частоту дискретизации (sample_rate)
    audio, sample_rate = librosa.load(audio_path, sr=None)  # sr=None означает использование оригинальной частоты файла

    # --- Шаг 2: Инициализация распознавателя и подготовка для работы с аудиофайлом ---
    
    recognizer = sr.Recognizer()  # Создаем объект распознавателя речи из библиотеки SpeechRecognition
    
    # Список для хранения результатов транскрипции
    transcription_results = []

    # --- Шаг 3: Чтение аудиофайла с помощью SpeechRecognition ---
    
    # Открываем аудиофайл с помощью `sr.AudioFile` для последующего распознавания
    with sr.AudioFile(audio_path) as source:
        
        # Считываем весь аудиофайл целиком в объект `audio_data`
        audio_data = recognizer.record(source)

        # --- Шаг 4: Попытка распознавания речи ---
        
        try:
            # Распознаем русский текст с помощью API Google
            text = recognizer.recognize_google(audio_data, language="ru-RU")

            # Сохраняем результат в список транскрипций с временной меткой 0
            transcription_results = [{'text': text, 'timestamp': 0}]

        # --- Обработка ошибок распознавания ---
        
        # Если речь не распознана (например, тишина или неразборчивый текст)
        except sr.UnknownValueError:
            transcription_results = [{'text': "[Не удалось распознать]", 'timestamp': 0}]
        
        # Если возникла ошибка при подключении или запросе к API Google
        except sr.RequestError as e:
            print(f"Ошибка API распознавания речи: {e}")
            transcription_results = [{'text': "[Ошибка API]", 'timestamp': 0}]

    # Возвращаем список результатов транскрипции
    return transcription_results

# Функция для анализа тональности текста (позитивная, негативная, нейтральная)
def analyze_sentiment(transcriptions):
    """
    Выполняет анализ тональности для каждой транскрипции с использованием модели "blanchefort/rubert-base-cased-sentiment".

    Аргументы:
    transcriptions — список транскрипций, каждая из которых представлена как словарь с ключами:
        - 'text': текст, который нужно проанализировать.
        - 'timestamp': временная метка начала этой транскрипции (например, для синхронизации с видео).

    Возвращает:
    sentiment_results — список словарей, каждый из которых содержит:
        - 'time': временная метка транскрипции.
        - 'text': исходный текст транскрипции.
        - 'sentiment': метка тональности текста (POSITIVE, NEGATIVE, или NEUTRAL).
        - 'confidence': уверенность модели в данной метке.
    """

    # --- Инициализация модели анализа тональности ---
    
    # Создаем объект анализа тональности (sentiment analyzer), используя предобученную модель на русском языке
    # Модель "blanchefort/rubert-base-cased-sentiment" обучена для классификации текста на POSITIVE, NEGATIVE, NEUTRAL.
    sentiment_analyzer = pipeline("sentiment-analysis", model="blanchefort/rubert-base-cased-sentiment")

    # Инициализация пустого списка для хранения результатов анализа
    sentiment_results = []

    # --- Проход по каждой транскрипции в списке ---
    
    for item in transcriptions:
        text = item['text']  # Извлекаем текст транскрипции для анализа
        timestamp = item['timestamp']  # Извлекаем временную метку транскрипции

        # --- Выполнение анализа тональности ---
        
        # Анализируем текст с помощью модели и получаем список с результатом
        # sentiment[0] содержит словарь с двумя ключами:
        # - 'label': метка тональности (например, 'POSITIVE', 'NEGATIVE', 'NEUTRAL').
        # - 'score': уверенность модели в данной метке (значение от 0 до 1).
        sentiment = sentiment_analyzer(text)

        # --- Сохранение результата в список ---
        
        sentiment_results.append({
            "time": timestamp,  # Временная метка транскрипции
            "text": text,  # Исходный текст транскрипции
            "sentiment": sentiment[0]['label'],  # Метка тональности (например, 'POSITIVE')
            "confidence": sentiment[0]['score']  # Уверенность модели в предсказанной метке
        })

    # Возвращаем список с результатами анализа тональности
    return sentiment_results



# Функция для создания библиотеки ключевых слов и их вариантов
def build_keyword_library():
    """
    Создает и возвращает библиотеку ключевых слов с их синонимами и вариантами написания.

    Возвращает:
    Словарь (dictionary), где:
    - Ключ — основное ключевое слово (например, "тестостерон").
    - Значение — список синонимов и вариантов написания для этого ключевого слова.
    
    Пример:
    {
        "тестостерон": ["тест", "testosterone", "тестостерончик", "hormone"],
        "витамин": ["витамины", "vitamin", "вит", "виташка"],
        ...
    }
    """
    
    # --- Создание и инициализация словаря ключевых слов ---
    
    # Формируем словарь, в котором каждому ключевому слову соответствуют его синонимы и альтернативные варианты написания
    keyword_library = {
        "тестостерон": ["тест", "testosterone", "тестостерончик", "hormone"],  # Варианты написания и переводы
        "витамин": ["витамины", "vitamin", "вит", "виташка"],  # Различные формы и упрощения слова "витамин"
        "женщина": ["женщины", "девушка", "баба", "girl", "female"],  # Синонимы и переводы для "женщина"
        "контакты": ["связь", "relationship", "отношения", "контакт"],  # Различные слова, связанные с контактом и общением
        "сахар": ["сахарок", "сахарочек", "sugar", "суг", "сах", "glucose"],  # Варианты написания и переводы слова "сахар"
        "наука": ["цинк", "магний"]  # Примеры элементов, которые часто упоминаются в контексте науки и медицины
    }

    # --- Возвращение созданной библиотеки ключевых слов ---
    
    return keyword_library  # Возвращаем словарь с ключевыми словами и их синонимами


# Функция для расширения библиотеки ключевых слов за счет добавления новых синонимов и сленговых терминов
def add_synonyms_and_slurs_to_library(keyword_library):
    """
    Расширяет библиотеку ключевых слов, добавляя новые синонимы, сленговые и иностранные варианты написания.

    Аргументы:
    keyword_library — исходный словарь с ключевыми словами и их синонимами, который нужно расширить.

    Возвращает:
    Обновленную библиотеку с добавленными синонимами и дополнительными вариантами.
    Пример:
    {
        "тестостерон": ["тест", "testosterone", "тестостерончик", "hormone", "тесто", "стера", "testo"],
        "женщина": ["женщины", "девушка", "баба", "girl", "female", "леди", "дамочка", "мисс", "мадам"],
        ...
    }
    """

    # --- Шаг 1: Определение новых синонимов и жаргонных терминов ---
    
    # Создаем словарь с дополнительными терминами для расширения ключевых слов.
    # Ключи — это основные ключевые слова, а значения — списки новых синонимов, сленгов и переводов.
    additional_terms = {
        "тестостерон": ["тесто", "стера", "testo"],  # Новые сленговые и сокращенные формы для "тестостерон"
        "женщина": ["леди", "дамочка", "мисс", "мадам"],  # Дополнительные термины и обращения для "женщина"
        "контакты": ["коннект", "connection", "линк", "link"],  # Сленговые и английские термины для контактов и связей
        "сахар": ["сладость", "сладкий", "sweet", "сладкоежка"],  # Связанные термины и описания для "сахар"
        "коуч": ["тренер", "наставник"]  # Синонимы для термина "коуч"
    }

    # --- Шаг 2: Обновление существующей библиотеки новыми терминами ---
    
    # Проходим по каждому ключевому слову и его новым терминам из словаря `additional_terms`
    for keyword, new_terms in additional_terms.items():
        
        # Если ключевое слово уже присутствует в библиотеке `keyword_library`, то расширяем его список новыми терминами
        if keyword in keyword_library:
            keyword_library[keyword].extend(new_terms)  # Добавляем новые термины к существующему списку синонимов
        else:
            # Если ключевое слово отсутствует в библиотеке, добавляем его как новый элемент
            keyword_library[keyword] = new_terms  # Создаем новую запись со списком дополнительных терминов

    # --- Возвращение обновленной библиотеки ---
    
    return keyword_library  # Возвращаем обновленную библиотеку ключевых слов


# Функция для извлечения ключевых событий на основе списка транскрипций и библиотеки ключевых слов
def extract_key_events(transcriptions, keyword_library=None):
    """
    Извлекает ключевые события из транскрипций на основе совпадений с ключевыми словами из библиотеки.

    Аргументы:
    transcriptions — список транскрипций, каждая из которых представлена как словарь с ключами:
        - 'text': текст, который нужно проанализировать.
        - 'timestamp': временная метка начала этой транскрипции (например, для синхронизации с видео).
    keyword_library — словарь с ключевыми словами и их синонимами.
        Если не передан, то создается стандартная библиотека с помощью функций `build_keyword_library` и `add_synonyms_and_slurs_to_library`.

    Возвращает:
    key_events — список словарей, каждый из которых содержит:
        - 'timestamp': временная метка транскрипции.
        - 'event': описание события с указанием найденного ключевого слова и основного термина.
        - 'context': исходный текст транскрипции, в котором было найдено ключевое слово.
    """

    # --- Шаг 1: Инициализация библиотеки ключевых слов (если не передана) ---
    
    # Если библиотека ключевых слов не передана в аргументах, создаем её с помощью предопределенных функций
    if keyword_library is None:
        keyword_library = build_keyword_library()  # Создаем основную библиотеку ключевых слов
        keyword_library = add_synonyms_and_slurs_to_library(keyword_library)  # Расширяем библиотеку дополнительными синонимами

    # --- Шаг 2: Инициализация списка для хранения ключевых событий ---
    
    key_events = []  # Список для хранения всех найденных событий по ключевым словам

    # --- Шаг 3: Проход по каждой транскрипции для поиска совпадений с ключевыми словами ---
    
    for item in transcriptions:
        text = item['text']  # Извлекаем текст транскрипции
        timestamp = item['timestamp']  # Извлекаем временную метку транскрипции

        # --- Шаг 4: Проверка на наличие ключевых слов в тексте ---
        
        # Проходим по каждому ключевому слову и его синонимам в библиотеке
        for keyword, synonyms in keyword_library.items():
            
            # Проходим по основному ключевому слову и его синонимам (включаем их в общий список для поиска)
            for term in [keyword] + synonyms:
                
                # Проверяем, содержится ли текущее ключевое слово или его синоним в тексте транскрипции
                if term.lower() in text.lower():  # Игнорируем регистр при проверке
                    # --- Шаг 5: Добавление найденного события в список key_events ---
                    
                    key_events.append({
                        "timestamp": timestamp,  # Временная метка транскрипции
                        "event": f"Найдено ключевое слово: {term} (основное: {keyword})",  # Описание события
                        "context": text  # Исходный текст транскрипции, в котором найдено совпадение
                    })

    # --- Возвращение списка ключевых событий ---
    
    return key_events  # Возвращаем список всех найденных событий


# Функция для выполнения базового анализа звуковых характеристик аудиофайла
def analyze_soundscape(audio_path):
    """
    Выполняет базовый анализ звуковых характеристик аудиофайла с помощью RMS и спектральных признаков.
    
    Аргументы:
    audio_path — путь к аудиофайлу, который нужно проанализировать.
    
    Возвращает:
    Словарь (dictionary), содержащий основные аудиометрики:
    - 'rms': средняя корневая среднеквадратическая амплитуда (Root Mean Square).
    - 'spectral_centroid': средний спектральный центр (Centroid).
    - 'spectral_bandwidth': средняя спектральная ширина (Bandwidth).
    """

    # --- Шаг 1: Загрузка аудиофайла и получение волновой формы и частоты дискретизации ---
    
    # Загружаем аудиофайл с помощью `librosa.load`, возвращая волновую форму (y) и частоту дискретизации (sr)
    # `sr=None` означает, что будет использована оригинальная частота дискретизации файла
    y, sr = librosa.load(audio_path, sr=None)

    # --- Шаг 2: Вычисление базовых звуковых характеристик ---

    # 1. RMS (Root Mean Square) — среднеквадратическое значение амплитуды.
    # Это метрика громкости, которая измеряет интенсивность сигнала.
    rms = librosa.feature.rms(y=y).mean()  # Вычисляем RMS по всему аудиофайлу и берем среднее значение

    # 2. Spectral Centroid — спектральный центр тяжести, указывающий на "яркость" звука.
    # Чем выше значение, тем больше энергии сосредоточено в высоких частотах.
    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()  # Рассчитываем средний спектральный центр
    
    # 3. Spectral Bandwidth — спектральная ширина, показывающая диапазон частот, покрываемых сигналом.
    # Это мера ширины частотного спектра, определяющая "разброс" частот вокруг спектрального центра.
    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()  # Средняя ширина спектра

    # --- Шаг 3: Возвращение результатов в виде словаря ---
    
    return {
        "rms": float(rms),  # Преобразуем RMS в стандартный тип float для сериализации и вывода
        "spectral_centroid": float(spectral_centroid),  # Преобразуем спектральный центр в float
        "spectral_bandwidth": float(spectral_bandwidth)  # Преобразуем спектральную ширину в float
    }



# Функция для анализа аудиофайла и определения типов звуков с помощью модели CLAP
def analyze_clap(audio_path, num_top_classes=3, similarity_threshold=0.5):
    """
    Выполняет анализ аудиофайла с использованием модели CLAP, чтобы определить типы звуков в записи.

    Аргументы:
    audio_path — путь к аудиофайлу, который нужно проанализировать.
    num_top_classes — количество наиболее вероятных классов звуков, которые нужно вернуть (по умолчанию: 3).
    similarity_threshold — минимальный порог для значения похожести, чтобы класс считался значимым (по умолчанию: 0.5).

    Возвращает:
    top_classes — список с названиями звуковых классов, которые соответствуют аудиофайлу и превышают заданный порог похожести.
    """

    # --- Шаг 1: Инициализация модели CLAP ---

    # Создаем объект модели CLAP для анализа звука
    # Параметр 'use_cuda=False' указывает на использование CPU вместо GPU
    clap_model = CLAP(version='2022', use_cuda=False)

    # --- Шаг 2: Определение списка целевых классов звуков ---

    # Определяем список звуковых классов, которые модель может распознавать.
    # Эти метки будут использоваться для создания текстовых эмбеддингов, чтобы затем сравнить их с аудиоэмбеддингами.
    class_labels = [
        "Music", "Speech", "Ambient Noise", "Traffic", "Nature Sounds",  # Основные категории звуков
        "Footsteps", "People Talking", "Animal Sounds", "Vehicle Sounds",  # Звуки людей, транспорта и животных
        "Construction Noise", "Household Appliances", "Crowd Noise",  # Звуки стройки и бытовые шумы
        "Water Sounds", "Weather Sounds", "Clapping", "Siren", "Alarm",  # Природные и предупредительные звуки
        "Game Sounds", "Phone Notifications"  # Звуки игр и уведомлений
    ]

    # --- Шаг 3: Получение текстовых эмбеддингов для заданных классов звуков ---

    # Используем модель CLAP для получения эмбеддингов для каждого звукового класса из списка `class_labels`
    text_embeddings = clap_model.get_text_embeddings(class_labels)

    # --- Шаг 4: Загрузка и подготовка аудиофайла ---

    # Загружаем аудиофайл с помощью `librosa.load`, возвращая волновую форму (y) и частоту дискретизации (sr)
    y, sr = librosa.load(audio_path, sr=None)

    # Сохраняем временный аудиофайл в формате WAV (так как CLAP требует wav-формат)
    # `sf.write` записывает массив амплитуд `y` и частоту дискретизации `sr` в указанный файл 'temp_audio.wav'
    sf.write('temp_audio.wav', y, sr)

    # --- Шаг 5: Получение аудиоэмбеддингов для загруженного аудиофайла ---

    # Используем модель CLAP для получения аудиоэмбеддингов для временного WAV файла
    audio_embeddings = clap_model.get_audio_embeddings(['temp_audio.wav'])

    # --- Шаг 6: Расчет похожести между аудио и текстовыми эмбеддингами ---

    # Вычисляем степень похожести между аудиоэмбеддингами и текстовыми эмбеддингами (т.е., сравниваем аудио с каждым классом)
    similarities = clap_model.compute_similarity(audio_embeddings, text_embeddings)

    # Преобразуем объект PyTorch Tensor в numpy массив для дальнейшего анализа
    similarities = similarities.detach().numpy()  # `.detach()` отключает вычисление градиентов, чтобы скопировать данные

    # --- Шаг 7: Выбор наиболее вероятных классов на основе похожести ---

    # Получаем индексы классов, отсортированные по убыванию степени похожести (от самого похожего к менее похожему)
    top_indices = np.argsort(similarities[0])[::-1][:num_top_classes]

    # Список топовых классов, которые превышают порог `similarity_threshold`
    top_classes = [class_labels[i] for i in top_indices if similarities[0][i] > similarity_threshold]

    # --- Возвращение списка топовых классов ---

    return top_classes  # Возвращаем список звуковых классов, соответствующих аудиофайлу


# Функция для создания словарей ключевых слов и фраз для категорий контента
def build_label_dictionaries():
    """
    Создает словари ключевых слов и фраз для каждой категории контента.

    Категории контента (ярлыки):
    - 'highlights': Ключевые слова и фразы, указывающие на важные и интересные моменты.
    - 'base': Основная и базовая информация, которая носит стандартный или нейтральный характер.
    - '18+': Ключевые слова, которые связаны с взрослым контентом (например, сексуальный контент, насилие).
    - 'gray': Слова, указывающие на сомнительное или рискованное поведение (например, агрессия, обман).
    - 'black': Термины, связанные с запрещенной деятельностью (например, преступления, терроризм).

    Возвращает:
    Словарь (dictionary), где:
    - Ключ — метка категории контента (например, 'highlights', 'base').
    - Значение — список ключевых слов и фраз, относящихся к этой категории.
    
    Пример:
    {
        "highlights": ["важно", "интересно", "круто", "обратите внимание", "факт", "узнать больше"],
        "base": ["основы", "обзор", "база", "стандарт", "нормально"],
        ...
    }
    """

    # --- Создание словаря категорий контента с их ключевыми словами ---
    
    return {
        # Ключевые слова и фразы, указывающие на важные и интересные моменты
        "highlights": ["важно", "интересно", "круто", "обратите внимание", "факт", "узнать больше"],

        # Основная и базовая информация, которую можно отнести к стандартному или нейтральному контенту
        "base": ["основы", "обзор", "база", "стандарт", "нормально"],

        # Ключевые слова, связанные с контентом для взрослых (18+), такими как секс, насилие или откровенные материалы
        "18+": ["сексуальный", "секс", "обнаженный", "мат", "насилие", "убийство"],

        # Термины, указывающие на сомнительное, агрессивное или рискованное поведение
        "gray": ["опасность", "спорно", "сомнительно", "риск", "агрессия", "обман", "лживый"],

        # Ключевые слова, связанные с незаконной или запрещенной деятельностью, такой как преступления или терроризм
        "black": ["запрещено", "преступление", "терроризм", "наркотики", "экстремизм", "убийство", "расизм"]
    }


# Функция для присвоения меток категории каждому текстовому сегменту на основе ключевых слов
def label_text_based_on_content(transcriptions, label_dicts):
    """
    Присваивает каждому текстовому сегменту метку категории на основе содержания текста.

    Аргументы:
    transcriptions — список транскрипций, каждая из которых представлена как словарь с ключами:
        - 'text': текст, который нужно проанализировать.
        - 'timestamp': временная метка начала этой транскрипции.
    
    label_dicts — словарь с категориями и ключевыми словами, структура:
        - Ключ: название категории (например, 'highlights', '18+').
        - Значение: список ключевых слов, относящихся к этой категории.

    Возвращает:
    labeled_transcriptions — список меток категорий, присвоенных каждому текстовому сегменту.
    
    Пример:
    Входные данные:
    transcriptions = [
        {"text": "Это очень важный момент", "timestamp": "00:01:23"},
        {"text": "Этот контент относится к базовым знаниям", "timestamp": "00:02:30"}
    ]
    
    label_dicts = {
        "highlights": ["важный", "интересно", "обратите внимание"],
        "base": ["базовый", "стандарт", "основы"]
    }
    
    Возвращает:
    ['highlights', 'base']
    """

    # --- Инициализация списка для хранения меток ---
    
    labeled_transcriptions = []  # Список для хранения всех меток категорий для каждого сегмента текста

    # --- Проход по каждой транскрипции в списке ---
    
    for item in transcriptions:
        # Приводим текст транскрипции к нижнему регистру для удобства поиска (игнорирование регистра)
        text = item['text'].lower()
        
        # Список для хранения меток, которые соответствуют текущей транскрипции
        labels = []

        # --- Проверка текста на наличие ключевых слов из каждой категории ---
        
        for label, keywords in label_dicts.items():
            # Проверяем, содержит ли текст хотя бы одно ключевое слово из текущей категории
            if any(keyword in text for keyword in keywords):
                labels.append(label)  # Если совпадение найдено, добавляем метку категории

        # --- Присваивание метки 'base', если другие метки не найдены ---
        
        # Если не найдено ни одной метки, присваиваем категорию "base" (базовая категория)
        if not labels:
            labels.append("base")

        # --- Сохранение меток для текущей транскрипции ---
        
        # Добавляем все найденные метки (или базовую метку) в общий список меток
        labeled_transcriptions.extend(labels)  # Используем extend, чтобы добавить метки в один общий список

    # --- Возвращение списка всех меток ---
    
    return labeled_transcriptions  # Возвращаем список всех меток категорий для каждого сегмента текста



# Функция для сохранения результатов анализа в JSON файл
def save_results_to_json(video_name, transcriptions, summary_results, sentiment_results,
                         soundscape_results, clap_results, key_events, labeled_transcriptions, output_file):
    """
    Сохраняет результаты анализа видео в формате JSON.

    Аргументы:
    video_name — имя видео, для которого выполняется сохранение результатов.
    transcriptions — список транскрипций текста, включающий временные метки и текстовые сегменты.
    summary_results — список результатов суммаризации текста.
    sentiment_results — список результатов анализа тональности (sentiment analysis).
    soundscape_results — базовые аудиометрики, такие как RMS и спектральные признаки.
    clap_results — результаты анализа звуковых классов с помощью модели CLAP.
    key_events — список ключевых событий, найденных на основе анализа ключевых слов.
    labeled_transcriptions — список меток категорий, присвоенных каждому текстовому сегменту.
    output_file — путь к выходному файлу, в который будут сохранены результаты (формат JSON).

    Возвращает:
    Ничего не возвращает. Сохраняет результаты в указанный JSON файл.
    """

    # --- Шаг 1: Проверка наличия существующего файла и загрузка данных ---
    
    # Если выходной файл уже существует, читаем его содержимое и загружаем данные
    if os.path.exists(output_file):
        with open(output_file, "r", encoding="utf-8") as f:
            data = json.load(f)  # Загружаем существующие данные из JSON-файла
    else:
        # Если файл не существует, инициализируем пустой словарь
        data = {}

    # --- Шаг 2: Инициализация новой записи для текущего видео (если не существует) ---
    
    # Если текущего видео (по его имени) еще нет в данных, добавляем новую запись
    if video_name not in data:
        data[video_name] = {}  # Создаем пустой словарь для хранения результатов анализа для данного видео

    # --- Шаг 3: Заполнение данных по каждому анализу ---

    # Сохраняем транскрипции с временными метками и текстом
    data[video_name]["transcriptions"] = transcriptions

    # Сохраняем результаты суммаризации текста
    data[video_name]["summary"] = summary_results

    # Сохраняем результаты анализа тональности (sentiment analysis)
    data[video_name]["sentiment_analysis"] = sentiment_results

    # Сохраняем базовые аудиометрические характеристики, такие как RMS и спектральные признаки
    data[video_name]["soundscape_analysis"] = soundscape_results

    # Сохраняем результаты предсказания звуковых классов с помощью модели CLAP
    data[video_name]["clap_analysis"] = clap_results

    # Сохраняем ключевые события, найденные на основе ключевых слов
    data[video_name]["key_events"] = key_events

    # Сохраняем метки категорий, присвоенные каждому текстовому сегменту
    data[video_name]["labeled_transcriptions"] = labeled_transcriptions

    # --- Шаг 4: Запись данных обратно в JSON файл ---
    
    # Открываем файл для записи (перезаписываем существующие данные или создаем новый)
    with open(output_file, "w", encoding="utf-8") as f:
        # Записываем данные в JSON-файл с параметром `ensure_ascii=False` для корректной работы с кириллицей
        json.dump(data, f, ensure_ascii=False, indent=4)  # Параметр `indent=4` задает красивое форматирование

    # --- Сообщение об успешном сохранении ---
    
    print(f"Результаты для видео '{video_name}' успешно сохранены в {output_file}")


# Основная функция для анализа аудио, извлеченного из видео, и сохранения результатов
def process_video_to_audio_analysis(video_path, output_path, start_time=0, end_time=None):
    """
    Выполняет полный анализ аудиофайла, извлеченного из видео, и сохраняет результаты в JSON файл.

    Аргументы:
    video_path — путь к видеофайлу, который нужно проанализировать.
    output_path — путь к выходному JSON файлу для сохранения результатов.
    start_time — начальная точка анализа (в секундах) (по умолчанию: 0).
    end_time — конечная точка анализа (в секундах) (по умолчанию: None, то есть до конца видео).

    Возвращает:
    Ничего не возвращает. Сохраняет все результаты в указанный выходной файл JSON.
    """

    # --- Шаг 1: Получение имени видео без расширения ---
    
    # Извлекаем имя видеофайла (без расширения) для использования в структуре выходного файла
    video_name = os.path.splitext(os.path.basename(video_path))[0]

    # Путь к выходному JSON файлу
    json_output_file = output_path

    # --- Шаг 2: Извлечение аудио из видео ---

    # Используем функцию extract_audio_from_video, чтобы извлечь аудиодорожку из указанного видеофайла
    extracted_audio_path = extract_audio_from_video(video_path)

    # --- Шаг 3: Проверка успешного извлечения аудиодорожки ---

    if extracted_audio_path:  # Если извлечение прошло успешно (путь к аудиофайлу не пустой)
        
        # --- Шаг 4: Анализ аудиофайла и его содержимого ---

        # 1. Распознавание речи и получение транскрипций
        transcriptions = split_audio_and_transcribe(extracted_audio_path)

        # 2. Генерация суммаризаций текста на основе транскрипций
        summary_results = generate_summary_russian(transcriptions)

        # 3. Анализ тональности (sentiment analysis) для каждого сегмента транскрипции
        sentiment_results = analyze_sentiment(transcriptions)

        # 4. Выполнение базового анализа звуковых характеристик (RMS, спектральный центр и ширина)
        soundscape_results = analyze_soundscape(extracted_audio_path)

        # 5. Определение типов звуков с помощью модели CLAP (анализ шумов, речи и других типов звуков)
        clap_results = analyze_clap(extracted_audio_path)

        # 6. Извлечение ключевых событий на основе совпадений с ключевыми словами из библиотеки
        key_events = extract_key_events(transcriptions)

        # 7. Присвоение меток транскрипциям на основе содержания текста (категоризация)
        labeled_transcriptions = label_text_based_on_content(transcriptions, build_label_dictionaries())

        # --- Шаг 5: Сохранение всех результатов анализа в выходной JSON файл ---

        # Сохраняем результаты в указанный JSON файл
        save_results_to_json(
            video_name, transcriptions, summary_results, sentiment_results,
            soundscape_results, clap_results, key_events, labeled_transcriptions, json_output_file
        )

    else:
        # Если аудио не было извлечено, выводим сообщение об ошибке
        print("Аудио не было извлечено.")

# Основной блок кода, который запускается, когда скрипт выполняется напрямую (например, через консоль)
if __name__ == "__main__":
    """
    Если скрипт вызывается напрямую, то этот блок отвечает за чтение аргументов командной строки,
    вызов основной функции и выполнение анализа видео.
    """

    # --- Шаг 1: Инициализация парсера аргументов ---

    # Создаем объект для парсинга аргументов командной строки
    parser = argparse.ArgumentParser(description="Анализ аудио и видео контента.")
    
    # Добавление аргументов командной строки:
    # 1. Путь к видеофайлу (обязательный аргумент)
    parser.add_argument("video_path", type=str, help="Путь к видеофайлу.")

    # 2. Имя выходного JSON файла для сохранения результатов (обязательный аргумент)
    parser.add_argument("output_file", type=str, help="Имя выходного файла JSON.")

    # --- Шаг 2: Парсинг аргументов и передача их в переменные ---

    # Разбираем аргументы, переданные через командную строку, и сохраняем их в объект `args`
    args = parser.parse_args()

    # --- Шаг 3: Вызов основной функции анализа видео ---

    # Передаем аргументы, полученные из командной строки, в функцию анализа видео
    process_video_to_audio_analysis(args.video_path, args.output_file)
